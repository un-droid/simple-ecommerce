name: AI Test (Manual)

on:
  workflow_dispatch:  # Only manual trigger
    inputs:
      test_description:
        description: 'Custom test instructions (optional)'
        required: false
        default: ''

jobs:
  ai-test:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          
      - name: Install dependencies
        run: |
          npm ci
          # Install required packages
          npm install @anthropic-ai/sdk
          npx playwright install chromium
          
      - name: Start application
        run: |
          npm run dev &
          echo "Waiting for app to start..."
          npx wait-on http://localhost:3000 --timeout 60000
          echo "App is running!"
          
      - name: Start Playwright MCP Server
        run: |
          echo "Starting Playwright MCP server..."
          npx @playwright/mcp@latest --headless --port 8931 &
          echo $! > mcp-server.pid
          sleep 5  # Give server time to start
          echo "MCP server started on port 8931"
          
      - name: Run AI Tests with MCP
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          # Create test script that connects to MCP server
          cat > run-ai-test.js << 'EOF'
          const Anthropic = require('@anthropic-ai/sdk');
          const http = require('http');
          
          const client = new Anthropic({
            apiKey: process.env.ANTHROPIC_API_KEY,
          });
          
          async function runTest() {
            const customInstructions = process.argv[2];
            
            const instructions = customInstructions || `
              Test the e-commerce application at http://localhost:3000:
              - Navigate to homepage
              - Check all main elements load
              - Test navigation links
              - Try to add items to cart
              - Test checkout flow
              - Test payment method page
              - Test order complete page
              - Check breadcrumbs work
              - Report any issues found
              
              For each test, report:
              - What was tested
              - Pass/Fail status
              - Any errors encountered
            `;
            
            console.log('Starting AI-driven tests...\n');
            console.log('Test Instructions:', instructions, '\n');
            
            try {
              // Call Claude to analyze and provide test strategy
              const response = await client.messages.create({
                model: 'claude-3-5-sonnet-20241022',
                max_tokens: 4000,
                messages: [{
                  role: 'user',
                  content: `You have access to a Playwright MCP server running at http://localhost:8931/mcp that can control a browser.
                  
                  ${instructions}
                  
                  Please provide a detailed test report with:
                  1. Test execution summary
                  2. Each test case with Pass/Fail status
                  3. Any bugs or issues found
                  4. Screenshots of key pages if possible
                  5. Recommendations for improvements
                  
                  Note: Since we're using headless mode, focus on functional testing rather than visual testing.`
                }]
              });
              
              console.log(response.content[0].text);
              
              // Save results
              require('fs').writeFileSync('test-results.md', 
                `# AI Test Results\n\n${response.content[0].text}`
              );
              
            } catch (error) {
              console.error('Error during testing:', error.message);
              process.exit(1);
            }
          }
          
          runTest();
          EOF
          
          # Use custom instructions if provided, otherwise use default
          TEST_INSTRUCTIONS="${{ github.event.inputs.test_description }}"
          
          echo "Running AI tests..."
          node run-ai-test.js "$TEST_INSTRUCTIONS"
          
          echo "Test completed!"
          
      - name: Alternative Direct Playwright Test
        if: failure()  # Run this if the above fails
        run: |
          echo "Running fallback Playwright test..."
          
          cat > direct-test.js << 'EOF'
          const { chromium } = require('playwright');
          
          (async () => {
            const browser = await chromium.launch({ headless: true });
            const page = await browser.newPage();
            
            const results = [];
            
            // Test 1: Homepage
            await page.goto('http://localhost:3000');
            results.push('âœ… Homepage loads successfully');
            
            // Test 2: Check for main elements
            const hasNav = await page.$('nav') !== null;
            results.push(hasNav ? 'âœ… Navigation found' : 'âŒ Navigation missing');
            
            const hasMain = await page.$('main') !== null;
            results.push(hasMain ? 'âœ… Main content found' : 'âŒ Main content missing');
            
            // Test 3: Check for buttons/links
            const buttons = await page.$$('button');
            results.push(`â„¹ï¸ Found ${buttons.length} buttons`);
            
            const links = await page.$$('a');
            results.push(`â„¹ï¸ Found ${links.length} links`);
            
            // Save results
            const fs = require('fs');
            fs.writeFileSync('test-results.md', 
              '# Test Results\n\n' + results.join('\n')
            );
            
            console.log(results.join('\n'));
            
            await browser.close();
          })();
          EOF
          
          node direct-test.js
          
      - name: Display Results
        if: always()
        run: |
          echo "## Test Results ##"
          cat test-results.md || echo "No results file found"
          
      - name: Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ai-test-results-${{ github.run_number }}
          path: test-results.md
          retention-days: 30
          
      - name: Cleanup
        if: always()
        run: |
          # Kill MCP server if still running
          if [ -f mcp-server.pid ]; then
            kill $(cat mcp-server.pid) 2>/dev/null || true
          fi
          
      - name: Create Summary
        if: always()
        run: |
          echo "# ðŸ¤– AI Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Run Number:** ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "**Triggered by:** @${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
          echo "**Custom Instructions:** ${{ github.event.inputs.test_description || 'Default' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Test Output" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f test-results.md ]; then
            cat test-results.md >> $GITHUB_STEP_SUMMARY
          else
            echo "No test results found" >> $GITHUB_STEP_SUMMARY
          fi